I need to Thursday only 2:30 PM Thursday morning is that OK multiple so can you please 33 everybody references for the text any questions regarding syllabus?
OK alright today is to give you a very condensed version of the intent is to give you a very condensed overview of the whole course the intent is not for you to understand everything that I'm talking about create questions in your mind seems to be pretty good increasing the absorption of material is confront you with a lot of questions a lot of questions actually good it's not design so I'm done with a lot of information create questions and hopefully those questions would bother you so much that when I started answering them you're like OK finally now I get so OK so that's the method going through the technical details with intentionally you know Fast forward speed let's take a walk memory lane where we're at and you appreciate what we have achieved discovering Sometimes people ask me that what do you think we're going to? Proper AI. General. Probably sooner than what we think given what has happened, but nobody can really predict our trajectory. Think about flying. 70s kids, so you were supposed to have flying cars back then? Almost four years out, but now we have these. In some sense, really. Addictive devices. It's basically a supercomputer. So, so it's hard delete to imagine what's going to happen in the future, but when you look at the the past history of computing machines and intelligent machines. It's good to take a look at it. Do some perspective. Abacus machinery something simple really good. Mechanical intelligent machine. For example. Asteroids that basically concentric circles pretty good, even though they assumed that Earth is the center of the universe, which is not true. Predict celestial events. Things like. So. A lot of important events. Necklaces and so forth were being predicted by by this machinery. Um so. Important thing to understand is that you know there is a. Hardware side and there is an algorithm side. And hardware. Has been traditionally. Started with mechanical, right? For example, the. Never. Became functional, it was designed, but it never got to the point that it would start crunching numbers. But yeah. Work. In it as well. Progressing. Other types of computer optical computers and most. Importantly, which is something that is going to happen. This is computer, so people are thinking about you know how to use quantum effects for computing so. Talking about myself and revealing my brother ancient history. Talking about the 70s. Speech 11 one of the first computer programs. And then you have from the watch right now that these thousands of times were capable. Thousands of times. Things have moved in terms of hard work really, really fast. The hardware that was important for is going to be. Intelligent machines and what we talk about age of intelligent machines. There have been a lot of starts and stops and moves on breasts in terms of what AI has been and what it has done. The term AI itself. Cool turn. Conference. We thought that you know well. Predecessor, stop that. They're going to be intelligent. You cannot interview person and go through a series of if then. To get to the. With the base of their knowledge right that you swim, or if you're riding a bicycle interview, you cannot give me a series of if then statements that I can code into a robot and robot start swimming or riding a bicycle. Something was wrong with that mindset depending on. Intelligence. You may or may not be going to the right direction. Think about flights for anything. We're trying to. Some of them were just. Imagine machinery that never could fly. Some of them were trying to mimic nature, so obviously they started with flapping wing model that can work and now we have something that is in between right and we had wings. Rotating basically. Copy in the nature. Neural networks, which is the topic of this course. Is one of those things. Networks they were inspired by. My logical networks. Cartoon image of Realnetworks. We're not going to replicate. Ionic channels. Interesting things that are happening in network. Existing or not going to do that. Alright, so take a look at the landscape there. A I. Started talking about it. You know from systems and. Actually, if you think about it, the more advanced. Generic, but not very successful concepts. So. Some people say that. Maybe it is, but you can't. Good luck if you can create a passion. Logistic regression is familiar with the term. Again, something that's. Earlier in machine learning. Shallow learning. Starts with. Networks can be thought of as a formalistic regression. Chaleurs actually can be taught to create representations, which is how people still knowledge of. We're going to discuss later on. It's called auto encoders. So. High dimensional data into something very very dense. Think about it as sort of a compression and tries to project for dense representation that contains most in all the information. Is a representation. Future engineering. Itself is a bottleneck in designing. Intelligent machines. Anyway, so that that's something that we discovered earlier, and then we started specializing those autoencoders languages, dictation, learning mechanisms, and he got the deep learning. So if you think about it, you know we started. It was very generically working really well. Once something more specific work bold better and deep learning is a basically a. Very, very specialized. Branch of where we started from decades ago. OK, we talked about artificial neural networks. Green light computer. It's a brain like computer. It's not copied exactly from the brain. But it's not exactly. And. A lot of people this is funny, yeah, whatever. Something interesting in terms of everything in the world. Start looking like that. Or is it? Explain like that so that when we found out about gates you know back in the 50s along remove started building digital computers. People are like oh great is like digital computer and look at all those neurons they're like and boarding all their dogs, right? But that's what people thought. Brain is and then found out. No, it's not exactly like that. As I mentioned. So we got to where we're at right now. In the process. But networks. Machines that are simulated. Hard work because. Digital hardware. Demand early on for normal networks instead of having. We would have had way earlier. There were efforts to create. From University of Heidelberg. So, but it didn't go that far. Door very interesting to have a lot of problems. That's why we got to keep the story. Interesting excruciating. Simulates computer science skill that you need to get it to work in something that is inherently. Cereal. Misnomer. Talk about processing units for normal network. Well, thank you. Learning revolution and given how vastly superior it is compared to any other machine learning algorithms. We're talking about orders of magnitude. Several important complex applications like visual perception, word learning does better than. Previous lecture. I'm a convert myself. Still scratching our heads, why? Why is it working so well? Discovered. So it was not by design if people found. To get something to work before. This is obviously a joke. CS Major in their computer scientists? Information system, but the definition of the engineer. Again, this is not 100% true. It says that engineer is somebody who can use math without understanding so. That's good enough. Prove that. This is how it works. OK. Actually very very complex. A lot of things that we find hard. They're actually very easy for computers, computers. We're talking about one moment. Multiply. Random numbers. She's been working on the set of skills to impress girlfriends. By $5 calculator. And so networks create those control systems. So. Makes makes this architecture a lot kind of human life. Networks and multiply. Two sets of numbers. It's probably going to be very similar to it's going to get very close with people. Could not find exact. Go right so we could have the next generation computers that have moved. You know traditional and neural engines as a matter of fact you do. So your cell phone is a hybrid computer. First of all, the signal processing units and the DSP. It's really good. Moving forward. Yourself is a really good in things like augmented reality right now. Point your cellphone. That's something it understands what that depending on the application like Google Translate. Turn on your camera. Really useful if you're traveling. Language you points roadside and it's magically. I don't know if you got it or not. Remove the letters change in the translation in English in real time superscript. Sometimes. Translation is hilarious. So the reason is that you have a hybrid machine and the part that translates. Objects, understandings of the world start. There's a lot of pixels. Millions and millions of pixels actually text. It should translate. That's very important. It's really, really hard actually. How do you translate it in real time into another language? Those parts of the process, they're all done. And the reason that states your cell phones are so good at doing something like that is that whether the manufacturer of the chipset is the Qualcomm Apple, they have some sort of normal processing. Is designed to run role networks. It's been just a few years, years, you know. Shipped with that part of Silicon prebuilt. The reason how good neural networks are so you cannot live without. I'm so glad that you guys signed up so we can talk more about the magical. stuff. Attending conferences? Talk about remove dancing, neural networks. Life processing units are one of those incidents. Sounds like Doctor Evil sorts of experiments that I saw. Process it was. Portable column and Petri dish. Capitalize The researchers had figured out a way to reprogram the. Connections are doing something very simple. It's a novel, but I'm just telling you how. The research. That little brain tissue was doing like a flight simulator. Very simple but. Life along but so. But that is site, you know. Interfacing. Brain tissue is very important. This is something that is being hacked. There is an FDA approved device called Brain Games for quadriplegics. Brain. Quadriplegic and it's reads neural signals. Looking for neural network. Artificial neural networks translates the signals from the wetware neural network and you know. Versions of. Systems that are wired or working on. Wireless or Bluetooth version. I don't know why. Self driving cars I've worked on. Computer interfaces. So that's that's another very important. We're not going to talk about it, but I'm just introducing to the wealth of this and breadth of this. Very exciting technology. I don't know about you guys. Keep forgetting information. But that would be great. Just plug it in. Direct connection. So. Yeah, we talked a little bit about. Application image recognition and understanding. Language processing. If you're in the field. Massive amounts of video businesses. Social media. If you want to predict markets markets, very brainwashed. If you guys. We can talk a little bit about market analysis if we have time. Big part of the market. Directions are sentiment analysis was a sentiment in you heard about. Read it in your GameStop right? Just look at the indices that are being generated. Dow Jones 500. That does not give you enough information. Tweets. So if you want to build an engine that. A lot of applications understand is huge and if you have. Go ahead and just Google conversations that are coming out of GT3, which is, you know. The latest and greatest in natural language processing. Philosophical conversations about meaning of life. So that we have long. Sometimes it says something really strange. For most part it is. All sorts of businesses being built around this year, if you're right. If you're good. A lot of people talked about how monetized the technology has become. There are a lot of people that. Without having. Understanding of people and put together a system for you, but it can not very far. If you want to put together a system that does, you know Salt Lake problem as far as self driving car itself around cars. Robots on four wheels. It's really, really hard to solve that problem. That's why do you have? The best self driving car that you think it's going to be very logical, but it could decide to kill you to save hundred other people on the road. It's very complex and it's not just building a good self driving cars that people want to buy. So the different type of problem. Self driving cars that people buy Dragon card actually. So. Speech recognition. Digital system all deep learning. All those other applications. There are a lot of issues that also. Created by AI so. I'm not talking about. T1000 Skynet we're not there yet. Honestly, I don't know what we're gonna get. Within 100 years. Maybe I don't know. Would never happen. It was a symmetric solution to that problem because. We don't have to talk about that. It's a fascinating field, and that's when you. Think about playing a game of chess. You have to think like 10 steps ahead, but. That prediction is not just what you want to do. You have to incorporate into that prediction what the environment. In this case, your opponent is going. So we have. Within which you were learning agent list. That's the basis of reference form. The reason for some learning? Yes, without thinking. Statistical and shallow. We're gonna start from actually get up from shallow matters and just kind of make it deeper and deeper till we get. But the rookie mistake is too. Go with, you know the most heavy handed solution. A lot of times you can solve your problem, maybe with the leading system for blessings and just walk away. Just remember that. Statistical and shallow learnings still has its place and. Learning. More about. But we had deep learning. The history of neural networks because I lived through it so in 1983. Controlling was shared with multilayer neural networks that was designed by Fukushima to explain and solve visual perception. Never took off. I have a lot of data. That's why it never took off. We talked about how different neural networks are. With respect to an architecture like. Traditional. Architecture GPU. It's a lot easier for them to do a lot of matrix multiplication in parallel. So they're not perfect. That's why we have password processing units. Offering in video, by the way. It works better with deep learning. So that's why everybody is in video because. That's a lot of power. A lot of data because. Take pictures of dogs and cats. Uploaded on the Internet so. Hundreds of millions of pictures floating around, so we have massive datasets. The combination of the two old school neural networks. Gay. And. Jeff Hinton unfortunately. Anyway, that's. How we got here in terms of algorithmic inclusions because. Given how complex? We gotta talk about it more later. We needed a lot of regularization, sparsity, structure. We have to get rid of a lot of things that you don't need so. We talked about dropout and other techniques that make deep learning. Work a lot better than. Neural network does. So we talked about the size of datasets. Size of datasets that we have and how. Datasets out there. And. So. Big datasets, a lot of computing power. This is the introduction, so we're not gonna be like quote wild. May or may not happen. Because. Hopefully work. Not go extinct before we see that future because of other issues, but that aside. Just think about the trajectory of hard work. Let's think about transistor as a feature in neural network. So. Go first. Play with something I built myself. It was built with. Creative. Texas Instruments. 8000 nanometer process, meaning that each syllable feature the width was 3000. That's gigantic pocket, so they're using already 5 million euros. And. It had a whopping. 8000 transistors 10s of billions of transistors. So how did that happen? Slowing down. Like three packages double sided. Silicone manufacturing, and if you think about your cortex neocortex, that best word intelligence and then there is the. More basic functions in. Marion Brain or Cortex? If you spread it out, list directly part of the brain, the brain matter. Because he's a lot of surface and you have to be ready. If you spread it out. In terms of. Area. This is about. It has about 11:30 billion cells. You know, we don't know how many of them were active. Supporting role. You're very connected. So a lot of neurons here, but let's just project. Have doubled. Future numbers and future size and so forth. So that's where we are right now. Sometimes I'm smarter, sometimes or not. Level intelligence if you just project around 2040 we should have the hardware that is add capable of doing brain and after that space financial. So that's. Nick bostrom so. So that was. Overview of the landscape. Do it twice a week till end of the semester. Don't do that. 

They do something that is called heavy and learning. Have you learned? Neurons that fire together wire together that speed. Something very boring. If you're familiar with principal component analysis, it does a PCA and. It's it's just so anticlimatic. If you want to calculate principal components, all you have to do is to calculate eigenvalues and vectors. Composition, standard linear algebra. You don't. You don't need networks. So if any of you guys figures out. What is the next learning algorithm? Probably you're going to get word because. It has nothing to do with how you and I. Calculator. That's back propagation and. We don't have anything better that works, but. It's not very efficient. We talked about. Teacher neural network. That's when you hit those big GPU's. You have a GPU farm and these things are power hungry. Put stress on the power. That's why countries that they have power blackouts. Electricity is relatively cheap. Longoria these things are really hungry. Massive neural networks. Treatment. Very energy hungry process. The train model is exported into a very compact package. For example, the iOS developer. Drag and drop your iPhone into into your computer, run Xcode. Boom, yeah you have the model in your phone. It runs in real time. It's power efficient. So after the training is done activating that model and make it.


Energy. A lot of examples. That's why. Data is so important, that's why. Trying to get as much data as they can from you like providing free services because they need a lot of examples and there's no backdrop requires thousands and thousands of examples to learn something. However, humans are the opposite. Examples of something we get. So one of the major research areas is few shot learning or zero stop learning. Without having to train on thousands if not millions of examples was 1000, we're going to talk about during we're gonna take orange large datasets. We gotta jitter. We're going to make it a little bit rotated. A little bit noisier, a little bit sharper. Generally takes already large datasets and makes it much, much larger. Algorithms? Which is bad. I don't know if you expected this. Yes. So so. When we're talking about the back propagation, like I'm not sure if the brain or internally works that way, but like. Sometimes we have examples of backpropagation, unlike when we think that'll be left a key out somewhere and like we don't find it out there. So we try to retrace the path like. We go back to think that. I went to I must have captured like I came here. Then I went there so like so I guess even a brain kind of works. Uses backpropagation to some extent. The answer is no. When you think about something, it triggers another memory. and then
